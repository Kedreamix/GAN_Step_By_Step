# GAN Step By Step



![logo](https://img-blog.csdnimg.cn/dc199d960b704e0c9331376e069be96e.png#pic_center)

## å¿ƒè¡€æ¥æ½®

**[GSBS][6]**ï¼Œé¡¾åæ€ä¹‰ï¼Œæˆ‘å¸Œæœ›æˆ‘è‡ªå·±èƒ½å¤Ÿä¸€æ­¥ä¸€æ­¥çš„å­¦ä¹ GANã€‚GAN åˆå ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œæ˜¯æœ€è¿‘å‡ å¹´å¾ˆçƒ­é—¨çš„ä¸€ç§æ— ç›‘ç£ç®—æ³•ï¼Œä»–èƒ½ç”Ÿæˆå‡ºéå¸¸é€¼çœŸçš„ç…§ç‰‡ï¼Œå›¾åƒç”šè‡³è§†é¢‘ã€‚GANæ˜¯ä¸€ä¸ªå›¾åƒçš„å…¨æ–°çš„é¢†åŸŸï¼Œä»2014çš„GANçš„å‘å±•ç°åœ¨ï¼Œåœ¨è®¡ç®—æœºè§†è§‰ä¸­æ‰®æ¼”è¿™è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ï¼Œå¹¶ä¸”åˆ°æ¯å¹´éƒ½èƒ½äº§å‡ºå„è‰²å„æ ·çš„ä¸œè¥¿ï¼ŒGANçš„ç†è®ºå’Œå‘å±•éƒ½è›®å¤šçš„ã€‚æˆ‘æ„Ÿè§‰æœ€è¿‘æœ‰å¾ˆå¤šäººéƒ½åœ¨å­¦ä¹ GANï¼Œä½†æ˜¯å›½å†…å¯èƒ½ç¼ºå°‘æ¯”è¾ƒå¤šçš„GANçš„ç†è®ºåŠå…¶å®ç°ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæƒ³ç€å’Œå¤§å®¶ä¸€èµ·å­¦ä¹ ï¼Œå¹¶ä¸”æä¾›ä¸»æµæ¡†æ¶ä¸‹ **pytorch,tensorflow,keras** çš„ä¸€äº›å®ç°æ•™å­¦ã€‚

åœ¨ä¸€ä¸ª2016å¹´çš„ç ”è®¨ä¼šï¼Œ`æ¨ç«‹æ˜†`æè¿°ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œæ˜¯â€œ`æœºå™¨å­¦ä¹ è¿™äºŒåå¹´æ¥æœ€é…·çš„æƒ³æ³•`â€ã€‚

---

## Step4 CGAN (Conditional GAN)

### Conditional GAN

*Conditional Generative Adversarial Nets*

#### Authors

Mehdi Mirza, Simon Osindero

#### Abstract

Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.

[[Paper\]](https://arxiv.org/abs/1411.1784) [[code\]][]



![CGAN](https://img-blog.csdnimg.cn/img_convert/ce9570bfd6178ab06ff0ef6472ab5aa2.gif#pic_center)

CGANçš„å…¨ç§°å«**Conditional Generative Adversarial Nets**ï¼Œå…¶å®ä»è¿™ä¸ªåå­—æ¥çœ‹ï¼Œä¸æ­£å¸¸çš„GANæ¯”ï¼Œå¤šäº†ä¸€ä¸ªConditionalï¼Œconditionçš„æ„æ€å°±æ˜¯æ¡ä»¶ï¼Œæ­£å¸¸çš„GANæ¥è¯´ï¼Œå°±æ˜¯é€šè¿‡éšæœºå™ªå£°ç”Ÿæˆå›¾ç‰‡å³å¯ï¼Œä½†æ˜¯å¯¹äºCGANæ¥è¯´ï¼ŒåŠ äº†ä¸€äº›ç®€å•çš„æ¡ä»¶çº¦æŸï¼Œè¾“å…¥äº†æ ‡ç­¾ï¼ŒæŒ‡å®šå»ç”Ÿæˆç‰¹å®šæ ‡ç­¾çš„å›¾ç‰‡ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹ä¸€ä¸‹ä¸¤è€…çš„ç»“æ„ï¼Œå¯¹äºGANæ¥è¯´ï¼Œä¸¤è€…çš„åŒºåˆ«å°±æ˜¯å¤šäº†ä¸€ä¸ªcã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/33e16c2e1f57409ea60c98b777c9cf47.png)



ç”¨ä¸€å¥è¯æ¥æ€»ç»“CGANï¼Œ**æŠŠæ ‡ç­¾ä¸€èµ·é€è¿›ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œè®©ä»–ä»¬æ ¹æ®æ ‡ç­¾æ¥ç”Ÿæˆ/åˆ¤åˆ«ç»“æœã€‚**

[![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/59d1caa6abcb408aa2ca4be1c5f55da8.png)][3]





æˆ‘ä»¬å¯ä»¥çœ‹ä¸€çœ‹ï¼ŒåŸå§‹GANçš„æ ¸å¿ƒå…¬å¼ï¼š

![image-20190330002722695](https://tva1.sinaimg.cn/large/006tKfTcly1g1k4prcvzdj312i06m3za.jpg#pic_center)

å¯¹äºCGANæ¥è¯´ï¼Œå¦‚æœæˆ‘ä»¬å·²çŸ¥è¾“å…¥çš„ground truthçš„labelä¿¡æ¯,é‚£ä¹ˆæˆ‘ä»¬ä¾¿å¯ä»¥åœ¨è¿™ä¸ªåŸºç¡€ä¸Šç»“åˆæ¡ä»¶æ¦‚ç‡çš„å…¬å¼å¾—åˆ°CGANçš„ç›®æ ‡å‡½æ•°:

![image-20190330001423117](https://tva1.sinaimg.cn/large/006tKfTcly1g1k4c8vwu6j31fa0a2q5c.jpg#pic_center)

CGANåœ¨ç”Ÿæˆæ¨¡å‹Gå’Œåˆ¤åˆ«æ¨¡å‹Dä¸­åŒæ—¶åŠ å…¥æ¡ä»¶çº¦æŸyæ¥å¼•å¯¼æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹ã€‚æ¡ä»¶å¯ä»¥æ˜¯ä»»ä½•è¡¥å……çš„ä¿¡æ¯ï¼Œå¦‚ç±»æ ‡ç­¾ï¼Œå…¶å®ƒæ¨¡æ€çš„æ•°æ®ç­‰ï¼Œè¿™æ ·ä½¿å¾—GANèƒ½å¤Ÿæ›´å¥½åœ°è¢«åº”ç”¨äºè·¨æ¨¡æ€é—®é¢˜ï¼Œä¾‹å¦‚å›¾åƒè‡ªåŠ¨æ ‡æ³¨ã€‚

å‚è€ƒäº†ä¸‹[ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‘Conditional GAN (CGANï¼Œæ¡ä»¶GAN) è¯¦ç»†è§£è¯»][1]ï¼Œ å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé€šè¿‡å°†é¢å¤–ä¿¡æ¯yè¾“é€ç»™åˆ¤åˆ«æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹,ä½œä¸ºè¾“å…¥å±‚çš„ä¸€éƒ¨åˆ†,ä»è€Œå®ç°æ¡ä»¶GANã€‚åœ¨ç”Ÿæˆæ¨¡å‹ä¸­,å…ˆéªŒè¾“å…¥å™ªå£°p(z)å’Œæ¡ä»¶ä¿¡æ¯yè”åˆç»„æˆäº†è”åˆéšå±‚è¡¨å¾ã€‚å¯¹æŠ—è®­ç»ƒæ¡†æ¶åœ¨éšå±‚è¡¨å¾çš„ç»„æˆæ–¹å¼æ–¹é¢ç›¸å½“åœ°çµæ´»ã€‚ç±»ä¼¼åœ°ï¼Œæ¡ä»¶GANçš„ç›®æ ‡å‡½æ•°æ˜¯å¸¦æœ‰æ¡ä»¶æ¦‚ç‡çš„äºŒäººæå°æå¤§å€¼åšå¼ˆï¼ˆtwo-player minimax game ï¼‰ï¼š 

![image-20190330001521830](https://tva1.sinaimg.cn/large/006tKfTcly1g1k4d9g482j30u00uk0xq.jpg#pic_center)



## MNISTæ•°æ®é›†å®éªŒ

ç›¸è¾ƒäºåŸå§‹çš„GANï¼Œè¿™ä¸ªå¾ˆç®€å•ï¼Œåªéœ€è¦åœ¨è®­ç»ƒå’Œé¢„æµ‹çš„æ—¶å€™ï¼Œåœ¨ Generator å’Œ Discriminator çš„è¾“å…¥ç«¯å¤šç»™ä¸€ä¸ª inputï¼Œè¿™ä¸ª input ä½œç”¨å°±æ˜¯æä¾›ä¸€ä¸ªæ ‡ç­¾ã€‚ è®© Generator çŸ¥é“è¿™å¼ ç…§ç‰‡è¯¥ç”Ÿæˆä»€ä¹ˆï¼Œè®© Discriminator çŸ¥é“è¿™å¼ ç…§ç‰‡æˆ‘åº”è¯¥åˆ¤åˆ«æ˜¯ï¼šå®ƒæ˜¯å¦æ˜¯æ­¤æ ‡ç­¾ç±»åˆ«ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾åœ¨ä¸‹é¢è¿™ä¸ªæƒ…å†µä¸­,æ¡ä»¶ c æ˜¯ train,å›¾ç‰‡ x ä¹Ÿæ˜¯ä¸€å¼ æ¸…æ™°çš„ç«è½¦ç…§ç‰‡,é‚£ä¹ˆ Dçš„è¾“å‡ºå°±ä¼šæ˜¯ 1ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/c02f46acc40b40b4bb2384c714c7807f.png#pic_center)

è€Œåœ¨ä¸‹é¢ä¸¤ä¸ªæƒ…å†µä¸­,å·¦è¾¹è™½ç„¶è¾“å‡ºå›¾ç‰‡æ¸…æ™°,ä½†ä¸ç¬¦åˆæ¡ä»¶ c;å³è¾¹è¾“å‡ºå›¾ç‰‡ä¸çœŸå®ã€‚å› æ­¤ä¸¤ç§æƒ…å†µä¸­ D çš„è¾“å‡ºéƒ½ä¼šæ˜¯ 0ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/f873b870a4244c1fb540c776834a816d.png#pic_center)

æ‰€ä»¥æ”¹åŠ¨ç»å…¸GANçš„ç¨‹åº¦ç›¸å¯¹æ¯”è¾ƒå°‘ï¼Œè€Œæˆ‘ä»¬åœ¨ mnist æ•°æ®åŠ å·¥çš„æ—¶å€™ï¼Œè¿˜è¦é¢å¤–åšä¸€é“å·¥åºï¼Œé™¤äº†æ‹¿å‡ºæ‰‹å†™æ•°å­—å›¾ç‰‡ï¼Œè¿˜è¦å°†æ•°å­—æ ‡ç­¾ä¹Ÿæ‹¿å‡ºæ¥ã€‚

### ç”Ÿæˆç½‘ç»œ

ç”Ÿæˆå™¨çš„è¾“å…¥æœ‰ä¸¤ä¸ª,ä¸€ä¸ªæ˜¯é«˜æ–¯å™ªå£°noise,ä¸€ä¸ªæ˜¯ç”±æˆ‘å¸Œæœ›ç”Ÿæˆçš„å›¾ç‰‡çš„labelä¿¡æ¯,é€šè¿‡embeddingçš„æ–¹æ³•æŠŠlabelè°ƒæ•´åˆ°å’Œç±»åˆ«ç›¸åŒçš„ç»´åº¦,å†æ‹¼æ¥è¿™æ ·ä¾¿ä½¿å¾—noiseçš„è¾“å…¥æ˜¯å»ºç«‹åœ¨labelä½œä¸ºæ¡ä»¶çš„åŸºç¡€ä¸Šã€‚ ä¸æ‡‚embeddingçš„åŒå­¦å¯ä»¥è¿›è¡Œå­¦ä¹ ä¸€ä¸‹ï¼Œ[nn.Embeddingå±‚][5]

```python
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)

        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat, 0.8))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *block(opt.latent_dim + opt.n_classes, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )
        
    def forward(self, noise, labels):
        #ç”Ÿæˆå™¨çš„è¾“å…¥æœ‰ä¸¤ä¸ª
        # ä¸€ä¸ªæ˜¯é«˜æ–¯å™ªå£°noise
        # ä¸€ä¸ªæ˜¯ç”±æˆ‘å¸Œæœ›ç”Ÿæˆçš„å›¾ç‰‡çš„labelä¿¡æ¯
        # é€šè¿‡embeddingçš„æ–¹æ³•æŠŠlabelè°ƒæ•´åˆ°å’Œå™ªå£°ç›¸åŒçš„ç»´åº¦,åœ¨ä¹˜èµ·æ¥è¿™æ ·ä¾¿ä½¿å¾—noiseçš„è¾“å…¥æ˜¯å»ºç«‹åœ¨labelä½œä¸ºæ¡ä»¶çš„åŸºç¡€ä¸Š
        # Concatenate label embedding and image to produce input
        gen_input = torch.cat((self.label_emb(labels), noise), -1)
        img = self.model(gen_input)
        img = img.view(img.size(0), *img_shape)
        return img
```



### åˆ¤åˆ«ç½‘ç»œ

å¯¹äºæˆ‘ä»¬çš„åˆ¤åˆ«å™¨æ¥è¯´ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„ç½‘ç»œè¿˜æ˜¯ç±»ä¼¼çš„ï¼Œä½†æ˜¯å¤šäº†ä¸€ä¸ªEmbeddingå±‚ï¼Œè¿™æ ·æˆ‘ä»¬çš„åˆ¤åˆ«å™¨çš„è¾“å…¥åŒ…å«äº†å›¾ç‰‡ä¿¡æ¯å’Œèµ·å¯¹åº”çš„æ ‡ç­¾,æˆ‘ä»¬çš„åˆ¤åˆ«å™¨ä¸ä½†è¦åˆ¤åˆ«æ˜¯å¦çœŸå‡,è¿˜éœ€è¦åˆ¤åˆ«æ˜¯ä¸æ˜¯å›¾ç‰‡ç¬¦åˆå¯¹åº”çš„ç±»åˆ«ä¿¡æ¯

```python
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)

        self.model = nn.Sequential(
            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 512),
            nn.Dropout(0.4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 512),
            nn.Dropout(0.4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 1),
        )

    def forward(self, img, labels):
        # Concatenate label embedding and image to produce input
        # åˆ¤åˆ«å™¨çš„è¾“å…¥åŒ…å«äº†å›¾ç‰‡ä¿¡æ¯å’Œèµ·å¯¹åº”çš„æ ‡ç­¾,æˆ‘ä»¬çš„åˆ¤åˆ«å™¨ä¸ä½†è¦åˆ¤åˆ«æ˜¯å¦çœŸå‡,è¿˜éœ€è¦åˆ¤åˆ«æ˜¯ä¸æ˜¯å›¾ç‰‡ç¬¦åˆå¯¹åº”çš„ç±»åˆ«ä¿¡æ¯
        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)
        validity = self.model(d_in)
        return validity
```



### è®­ç»ƒè¿‡ç¨‹

```python
# ----------
#  Training
# ----------

for epoch in range(opt.n_epochs):
    epoch_step = len(dataloader)
    with tqdm(total = epoch_step,desc = f'Epoch {epoch+1:3d}/{opt.n_epochs:3d}',postfix=dict,mininterval=0.3) as pbar:
        for i, (imgs, labels) in enumerate(dataloader):

            batch_size = imgs.shape[0]

            # Adversarial ground truths
            # å¾—åˆ°å¯¹æŠ—çš„ground truthsï¼Œvalidå…¨ä¸º1ï¼Œ fakeå…¨ä¸º0
            valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)
            fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)

            # Configure input è½¬åŒ–æ•°æ®æ ¼å¼
            real_imgs = Variable(imgs.type(FloatTensor))
            labels = Variable(labels.type(LongTensor))

            # Sample noise and labels as generator input
            # zä¸ºè®¾ç½®çš„å™ªå£°ï¼Œç”¨æ­£æ€åˆ†å¸ƒæ¥éšæœºç”Ÿæˆï¼Œå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
            z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))
            gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))

            # Generate a batch of images
            # ç”Ÿæˆä¸€ä¸ªbatchçš„å›¾ç‰‡ï¼Œå¹¶ä¸”CGANåŠ å…¥ç”Ÿæˆçš„labels
            gen_imgs = generator(z, gen_labels)

            # ---------------------
            #  Train Discriminator è®­ç»ƒåˆ¤åˆ«å™¨
            # ---------------------

            optimizer_D.zero_grad()

            # Loss for real images
            validity_real = discriminator(real_imgs, labels)
            d_real_loss = adversarial_loss(validity_real, valid) # åˆ¤åˆ«çœŸå®å›¾ç‰‡çš„æŸå¤±

            # Loss for fake images
            validity_fake = discriminator(gen_imgs.detach(), gen_labels)
            d_fake_loss = adversarial_loss(validity_fake, fake) # åˆ¤åˆ«ç”Ÿæˆå›¾ç‰‡çš„æŸå¤±

            # Total discriminator loss
            d_loss = (d_real_loss + d_fake_loss) / 2

            d_x = validity_real.mean() # å¾—åˆ°åˆ¤åˆ«æ­£ç¡®å›¾ç‰‡çš„å‡†ç¡®ç‡
            d_g_z1 = validity_fake.mean() # å¾—åˆ°åˆ¤åˆ«é”™è¯¯å›¾ç‰‡çš„å‡†ç¡®ç‡

            d_loss.backward() # è¿›è¡Œåå‘ä¼ æ’­
            optimizer_D.step() # æ›´æ–°å‚æ•°


            # -----------------
            #  Train Generator è®­ç»ƒç”Ÿæˆå™¨
            # -----------------

            optimizer_G.zero_grad()

            # Loss measures generator's ability to fool the discriminator
            validity = discriminator(gen_imgs, gen_labels)
            g_loss = adversarial_loss(validity, valid) # ç”ŸæˆæŸå¤±

            d_g_z2 = validity.mean() # å¯¹ç”Ÿæˆå›¾ç‰‡åˆ¤åˆ«çš„æ¦‚ç‡

            g_loss.backward() # è¿›è¡Œåå‘ä¼ æ’­
            optimizer_G.step() # æ›´æ–°å‚æ•°

            # æ¯sample_intervalä¸ªbatchsåä¿å­˜ä¸€æ¬¡imagesï¼Œå›¾ç‰‡æ”¾åœ¨imagesæ–‡ä»¶å¤¹ä¸‹
            batches_done = epoch * len(dataloader) + i
            if batches_done % opt.sample_interval == 0:
                sample_image(n_row=10, batches_done=batches_done)
            
            # åˆ©ç”¨tqdmå®æ—¶çš„å¾—åˆ°æˆ‘ä»¬çš„æŸå¤±çš„ç»“æœ
            pbar.set_postfix(**{'D Loss' : d_loss.item(),
                                'G Loss' : g_loss.item(),
                                'D(x)': '{:.4f}'.format(d_x.item()),
                                'D(G(z))': '{:.4f} /{:.4f} '.format(d_g_z1, d_g_z2)})
            pbar.update(1)
        # è¿›è¡Œtensorboardå¯è§†åŒ–ï¼Œ å¾—åˆ°çœŸå®çš„å›¾ç‰‡
        # ä»¥åŠè®°å½•å„ä¸ªå€¼ï¼Œè¿™æ ·æœ‰åŠ©äºæˆ‘ä»¬åˆ¤æ–­æŸå¤±çš„å˜åŒ–
        img_grid = make_grid(real_imgs)
        tbwriter.add_image(tag='real_image',img_tensor=img_grid,global_step=epoch+1)
        # img_grid = make_grid(gen_imgs)
        tbwriter.add_scalar('D(x)',d_x.item(),global_step=epoch+1)
        tbwriter.add_scalar('D(G(z))',d_g_z2.item(),global_step=epoch+1)
        tbwriter.add_scalar('dist_loss', d_loss.item(),global_step=epoch+1)
        tbwriter.add_scalar('gene_loss',g_loss.item(),global_step=epoch+1)

```



### å®éªŒç»“æœ

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/02452709930f486da3672f8000d7b69a.png#pic_center)

ä»ç»“æœæˆ‘ä»¬å¯ä»¥çœ‹çš„å‡ºæ¥ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆå™¨èƒ½å¤Ÿå¾ˆå¥½çš„æ ¹æ®æˆ‘ä»¬æä¾›çš„labelä¿¡æ¯ç”Ÿæˆå¯¹åº”çš„å›¾åƒï¼Œæˆ‘ä»¬çš„CGANä½¿ç”¨éå¸¸ç®€å•çš„çº¿æ€§ç½‘ç»œï¼Œå¤šå±‚æ„ŸçŸ¥æœºï¼Œä½†æ˜¯ä¾ç„¶å¯ä»¥å¾—åˆ°æ‰€æœ‰labelå¯¹åº”çš„åˆ†å¸ƒçš„å›¾åƒçš„ï¼Œå¹¶ä¸”è¿™ä¹Ÿæ˜¯ä¸€ç§ç›‘ç£å­¦ä¹ ï¼ŒCGANå‘Šè¯‰æˆ‘ä»¬conditionæ˜¯å¾ˆé‡è¦çš„ï¼Œå¹¶ä¸”èƒ½åœ¨å¤šä¸ªé¢†åŸŸéƒ½èƒ½å–å¾—æ¯”è¾ƒå¥½çš„ç»“æœï¼Œæ¯”å¦‚è¯´å›¾åƒè‡ªåŠ¨æ ‡æ³¨ç­‰ç­‰ã€‚æ¡ä»¶GANæ€æƒ³ç¡®å®æ¯”è¾ƒç®€å•ï¼Œä½œè€…åœ¨paperé‡Œé¢ä¹Ÿè¯´äº†ï¼Œè¿™åªæ˜¯extremely preliminaryï¼Œå¹¶ä¸”ä¹‹åä¹Ÿ[å»¶ä¼¸å‡ºäº†å¾ˆå¤šä¸œè¥¿][1]ï¼Œä¹‹åä¹Ÿä¼šä¸€èµ·å­¦ä¹ ã€‚éƒ½çœ‹åˆ°è¿™é‡Œäº†ï¼Œå¦‚æœæ„Ÿå…´è¶£çš„å°ä¼™ä¼´ä»¬ï¼Œè§‰å¾—è¿˜ä¸é”™çš„è¯ï¼Œå¯ä»¥ä¸‰è¿æ”¯æŒä¸€ä¸‹ï¼Œç‚¹èµ+è¯„è®º+æ”¶è—ï¼Œä½ ä»¬çš„æ”¯æŒå°±æ˜¯æˆ‘æœ€å¤§çš„åŠ¨åŠ›å•¦ï¼ğŸ˜„





[1]: https://codeantenna.com/a/BZlitbtJ5d
[2]: https://zhuanlan.zhihu.com/p/23648795
[3]: https://mofanpy.com/tutorials/machine-learning/gan/cgan/	"Conditional GAN (CGAN) æœ‰æ¡ä»¶çš„ç”Ÿæˆ"
[4]: https://blog.csdn.net/u011534057/article/details/53409968
[5]: https://blog.csdn.net/qq_39540454/article/details/115215056 "nn.Embedding"
[6]: https://redamancy.blog.csdn.net/article/details/127082815  "GSBS"

[7]: https://github.com/Dreaming-future/GAN_Step_By_Step/blob/main/Step4/cgan/cgan.py